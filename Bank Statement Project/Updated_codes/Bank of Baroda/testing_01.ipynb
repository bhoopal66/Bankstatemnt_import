{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import tabula\n",
    "import camelot\n",
    "import pdfminer\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "try:\n",
    "    from cStringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Parsed\n"
     ]
    }
   ],
   "source": [
    "def tab(f):\n",
    "    try:\n",
    "        tables=tabula.read_pdf(f,\n",
    "                                  lattice=True,\n",
    "                                  pages=\"all\",\n",
    "                                  silent=True,\n",
    "                                  multiple_tables=True,\n",
    "                                  pandas_options={'header':None})\n",
    "        df = pd.DataFrame()\n",
    "        df = pd.concat([c for c in tables]).drop_duplicates()\n",
    "    except: pass\n",
    "    return df\n",
    "\n",
    "def process(df):\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    try:\n",
    "        df = df.replace(r'NA', np.nan, regex=True)\n",
    "    except:pass\n",
    "    try:\n",
    "        idx=[c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('balance').any(),axis=1)==True].index if c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('date').any(),axis=1)==True].index][0]\n",
    "        df.columns=df.iloc[idx]; df=df.iloc[idx+1:,:]; df.reset_index(drop=True, inplace=True)\n",
    "    except:\n",
    "        try:\n",
    "            idx=[c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('balance').any(),axis=1)==True].index if c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('description').any(),axis=1)==True].index][0]\n",
    "            df.columns=df.iloc[idx]; df=df.iloc[idx+1:,:]; df.reset_index(drop=True, inplace=True)\n",
    "        except:\n",
    "            print(\"\\nSBI Column Headers Missing\"); pass\n",
    "        try:\n",
    "            df = df.drop([\"Init.\"], axis=1)\n",
    "        except:\n",
    "            try:\n",
    "                df = df.drop([\"Branch Name\"], axis=1)\n",
    "            except:pass\n",
    "\n",
    "    df = df[~df.index.isin(df[df.apply(lambda row:row.astype(str).str.lower().str.contains('opening balance|transaction total|closing balance').any(),axis=1)==True].index)]\n",
    "    #df = pd.DataFrame(df.T.drop_duplicates().T)\n",
    "    #df.drop(df.nunique(dropna=False)[(df.nunique(dropna=False) == 1)].index, axis=1, inplace=True)\n",
    "\n",
    "    df.to_csv(\"parsed.csv\",index=0)\n",
    "    return df\n",
    "\n",
    "f = r\"C:\\Users\\MudraCircle\\Desktop\\bks_raw\\Parsing_testing\\ICICI\\files\\icici011pdf\"\n",
    "#f = r'C:\\Users\\MudraCircle\\Desktop\\bks_raw\\Parsing_testing\\ICICI\\files\\icici_meena_sarees\\icici08.pdf'\n",
    "try:\n",
    "    df = tab(f) ; df = process(df)\n",
    "    print(\"Parsed\")\n",
    "except:\n",
    "    print(\"Not Parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed..\n"
     ]
    }
   ],
   "source": [
    "f = r'C:/Users/MudraCircle/Desktop/bks_raw/Parsing_testing/ICICI/files/icici07.pdf'\n",
    "tables=camelot.read_pdf(f, flavor=\"lattice\", pages=\"all\")\n",
    "if len(tables) !=0 :\n",
    "    df=pd.DataFrame(); tmp=pd.DataFrame();\n",
    "    for i in range(len(tables)):\n",
    "        tmp=tables[i].df\n",
    "        if (tmp.shape[1]==8)|(tmp.shape[1]==7)|(tmp.shape[1]==6)|(tmp.shape[1]==5):\n",
    "            df=pd.concat([df,tmp]).drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "        else:\n",
    "            print(\"\\n different structure on page: \",i)\n",
    "            \n",
    "df=df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df=df[ df.isnull().sum(axis=1) < df.shape[1]-2].reset_index(drop=True)       \n",
    "df.drop(df.nunique(dropna=False)[(df.nunique(dropna=False) == 1)].index, axis=1,inplace=True)\n",
    "try:\n",
    "    idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "    df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)           \n",
    "except:\n",
    "        try:\n",
    "            idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "            df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)           \n",
    "        except:\n",
    "            try:\n",
    "                idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('narration').any(), axis=1) ==True].index ][0]\n",
    "                df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(    drop=True,inplace=True)           \n",
    "            except:       print(\"\\nProcess-Column headers missing\") \n",
    "                    \n",
    "df=df[~df.index.isin(df[df.apply(lambda row: row.astype(str).str.lower().str.contains('page:|account status|total|reason for return|inward clg|opening balance|statement of a/c').any(), axis=1) ==True].index)]\n",
    "df=pd.DataFrame(df.T.drop_duplicates().T)\n",
    "df.drop(df.nunique(dropna=False)[(df.nunique(dropna=False) == 1)].index, axis=1,inplace=True)\n",
    "     \n",
    "# try:\n",
    "#     dft=pd.DataFrame(df.iloc[:,0].dropna().unique().astype(int)).reset_index()\n",
    "#     if sum(dft.iloc[:,1])-sum(dft.iloc[:,0])==dft.shape[0] :\n",
    "#         df.drop(df.iloc[:,0].name, axis=1,inplace=True)\n",
    "# except:  pass\n",
    "df=df.drop_duplicates()\n",
    "df.to_csv(\"parsed.csv\", index=0)\n",
    "print(\"parsed..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed\n"
     ]
    }
   ],
   "source": [
    "def abc(a):\n",
    "    if type(a) == str:\n",
    "        if len(a.split(' '))==2:\n",
    "            z=a.split(' ')[1]\n",
    "        else:\n",
    "            z=a.split(' ')[0]\n",
    "    else:\n",
    "        z=a\n",
    "    return z\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def icici_p1(f):\n",
    "    tables=tabula.read_pdf(f,\n",
    "                              lattice=True,\n",
    "                              pages=\"all\",\n",
    "                              silent=True,\n",
    "                              multiple_tables=True,\n",
    "                              pandas_options={'header':None})\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.concat([c for c in tables]).drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def icici_p1_process(df):\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df = df[ df.isnull().sum(axis=1) < df.shape[1]-2].reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        idx=[c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('balance').any(),axis=1)==True].index if c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('date').any(),axis=1)==True].index][0]\n",
    "        df.columns=df.iloc[idx]; df=df.iloc[idx+1:,:]; df.reset_index(drop=True, inplace=True)\n",
    "    except:\n",
    "        try:\n",
    "            idx=[c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('balance').any(),axis=1)==True].index if c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('transaction').any(),axis=1)==True].index][0]\n",
    "            df.columns=df.iloc[idx]; df=df.iloc[idx+1:,:]; df.reset_index(drop=True, inplace=True)\n",
    "        except:\n",
    "            try:\n",
    "                idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('remarks').any(), axis=1) ==True].index ][0]\n",
    "                df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)\n",
    "            except:\n",
    "                print(\"\\nICICI Column Headers Missing\"); pass\n",
    "    try:\n",
    "        idx2 = [c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('page total').any(),axis=1)==True].index][0]    \n",
    "        df.drop(df.index[idx2:], inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df = df.loc[:, df.columns.notnull()]\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        dat=[c for c in df.columns if \"TRANSACTION DATE\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            dat=[c for c in df.columns if \"TXN DATE\" in str(c).upper() ][0]\n",
    "        except:\n",
    "            try:\n",
    "                dat=[c for c in df.columns if \"DATE\" in str(c).upper() ][0]\n",
    "            except:pass\n",
    "\n",
    "    try:\n",
    "        chq=[c for c in df.columns if \"CHQ\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            chq=[c for c in df.columns if \"CHEQUE\" in str(c).upper() ][0]\n",
    "        except:pass\n",
    "\n",
    "    try:\n",
    "        narr=[c for c in df.columns if \"REMARKS\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            narr=[c for c in df.columns if \"PARTICULARS\" in str(c).upper() ][0]\n",
    "        except:\n",
    "            try:\n",
    "                narr=[c for c in df.columns if \"DESCRIPTION\" in str(c).upper() ][0]\n",
    "            except:\n",
    "                try:\n",
    "                    narr=[c for c in df.columns if \"DETAILS\" in str(c).upper() ][0]\n",
    "                except:pass\n",
    "\n",
    "    try:\n",
    "        bal=[c for c in df.columns if \"BALANCE\" in str(c).upper() ][0]\n",
    "        df[\"bal\"]=df[bal].apply( lambda x: abc(x) )\n",
    "    except: print(\"\\nBalance columns missing\") \n",
    "\n",
    "    try:\n",
    "        wdl=[c for c in df.columns if \"WITHDRAW\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            wdl=[c for c in df.columns if \"DEBIT\" in str(c).upper() ][0]\n",
    "        except: pass \n",
    "\n",
    "    try:\n",
    "        dep=[c for c in df.columns if \"DEPOSIT\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            dep=[c for c in df.columns if \"CREDIT\" in str(c).upper() ][0]\n",
    "        except: pass\n",
    "\n",
    "    df[[wdl, dep]] = df[[wdl, dep]].replace({\"NA\":np.nan, \"-\":np.nan,\"0\":np.nan})\n",
    "\n",
    "    try:\n",
    "        auto=[c for c in df.columns if \"AUTOSWEEP\" in str(c).upper() ][0]\n",
    "        for j,i in enumerate(df[auto]):\n",
    "            if isnan(i) == False:\n",
    "                df[wdl][j] = df[auto][j]\n",
    "            else:\n",
    "                pass\n",
    "    except: pass\n",
    "\n",
    "    try:\n",
    "        rev=[c for c in df.columns if \"REVERSE\" in str(c).upper() ][0]\n",
    "        for j,i in enumerate(df[rev]):\n",
    "            if isnan(i) == False:\n",
    "                df[dep][j] = df[rev][j]\n",
    "            else:\n",
    "                pass\n",
    "    except: pass\n",
    "    \n",
    "    df[dep]=df[dep].apply( lambda x: x.split(' ')[0] if type(x) == str else x )\n",
    "    df[wdl]=df[wdl].apply( lambda x: x.split(' ')[0] if type(x) == str else x )\n",
    "    df[wdl]=df[wdl].astype(str).apply(lambda x: str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float) *-1\n",
    "    df[dep]=df[dep].astype(str).apply(lambda x: str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float)\n",
    "    df[bal]=df[bal].astype(str).apply(lambda x:str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float)\n",
    "\n",
    "    try:\n",
    "        for i in df.index:\n",
    "        #     # create new column\n",
    "        #     if \"Dr\" in df[\"new_column\"][i].astype(str):\n",
    "        #         df[bal][i] = df[bal][i]*-1\n",
    "            if df[\"bal\"][i] == \"Dr\":\n",
    "                df[bal][i] = df[bal][i]*-1\n",
    "            else:\n",
    "                pass\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop(['bal'], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop([auto], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop([rev], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    df = df[[dat,chq,narr,wdl,dep,bal]]\n",
    "    df.columns = [\"Xns Date\",\"Cheque No\",\"Narration\",\"Debits\",\"Credits\",\"Balance\"]\n",
    "        \n",
    "    df.to_csv(\"check.csv\", index=0)\n",
    "\n",
    "f = r\"C:\\Users\\MudraCircle\\Desktop\\bks_raw\\Parsing_testing\\ICICI\\files\\meena_icici\\icici01.pdf\"\n",
    "try:\n",
    "    df = icici_p1(f) ; df = icici_p1_process(df)\n",
    "    print(\"Parsed\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\",e)\n",
    "    print(\"Not Parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed\n"
     ]
    }
   ],
   "source": [
    "def abc(a):\n",
    "    if type(a) == str:\n",
    "        if len(a.split(' '))==2:\n",
    "            z=a.split(' ')[1]\n",
    "        else:\n",
    "            z=a.split(' ')[0]\n",
    "    else:\n",
    "        z=a\n",
    "    return z\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def icici_p1(f):\n",
    "    tables=tabula.read_pdf(f,\n",
    "                              lattice=True,\n",
    "                              pages=\"all\",\n",
    "                              silent=True,\n",
    "                              multiple_tables=True,\n",
    "                              pandas_options={'header':None})\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.concat([c for c in tables]).drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def icici_p1_process(df):\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df = df[ df.isnull().sum(axis=1) < df.shape[1]-2].reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        idx=[c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('balance').any(),axis=1)==True].index if c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('date').any(),axis=1)==True].index][0]\n",
    "        df.columns=df.iloc[idx]; df=df.iloc[idx+1:,:]; df.reset_index(drop=True, inplace=True)\n",
    "    except:\n",
    "        try:\n",
    "            idx=[c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('balance').any(),axis=1)==True].index if c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('transaction').any(),axis=1)==True].index][0]\n",
    "            df.columns=df.iloc[idx]; df=df.iloc[idx+1:,:]; df.reset_index(drop=True, inplace=True)\n",
    "        except:\n",
    "            try:\n",
    "                idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('remarks').any(), axis=1) ==True].index ][0]\n",
    "                df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)\n",
    "            except:\n",
    "                print(\"\\nICICI Column Headers Missing\"); pass\n",
    "    try:\n",
    "        idx2 = [c for c in df[df.apply(lambda row:row.astype(str).str.lower().str.contains('page total').any(),axis=1)==True].index][0]    \n",
    "        df.drop(df.index[idx2:], inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df = df.loc[:, df.columns.notnull()]\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        dat=[c for c in df.columns if \"TRANSACTION DATE\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            dat=[c for c in df.columns if \"TXN DATE\" in str(c).upper() ][0]\n",
    "        except:\n",
    "            try:\n",
    "                dat=[c for c in df.columns if \"DATE\" in str(c).upper() ][0]\n",
    "            except:pass\n",
    "\n",
    "    try:\n",
    "        chq=[c for c in df.columns if \"CHQ\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            chq=[c for c in df.columns if \"CHEQUE\" in str(c).upper() ][0]\n",
    "        except:pass\n",
    "\n",
    "    try:\n",
    "        narr=[c for c in df.columns if \"REMARKS\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            narr=[c for c in df.columns if \"PARTICULARS\" in str(c).upper() ][0]\n",
    "        except:\n",
    "            try:\n",
    "                narr=[c for c in df.columns if \"DESCRIPTION\" in str(c).upper() ][0]\n",
    "            except:\n",
    "                try:\n",
    "                    narr=[c for c in df.columns if \"DETAILS\" in str(c).upper() ][0]\n",
    "                except:pass\n",
    "\n",
    "    try:\n",
    "        bal=[c for c in df.columns if \"BALANCE\" in str(c).upper() ][0]\n",
    "        df[\"bal\"]=df[bal].apply( lambda x: abc(x) )\n",
    "    except: print(\"\\nBalance columns missing\") \n",
    "\n",
    "    try:\n",
    "        wdl=[c for c in df.columns if \"WITHDRAW\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            wdl=[c for c in df.columns if \"DEBIT\" in str(c).upper() ][0]\n",
    "        except: pass \n",
    "\n",
    "    try:\n",
    "        dep=[c for c in df.columns if \"DEPOSIT\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            dep=[c for c in df.columns if \"CREDIT\" in str(c).upper() ][0]\n",
    "        except: pass\n",
    "\n",
    "    df[[wdl, dep]] = df[[wdl, dep]].replace({\"NA\":np.nan, \"-\":np.nan,\"0\":np.nan})\n",
    "\n",
    "    try:\n",
    "        auto=[c for c in df.columns if \"AUTOSWEEP\" in str(c).upper() ][0]\n",
    "        for j,i in enumerate(df[auto]):\n",
    "            if isnan(i) == False:\n",
    "                df[wdl][j] = df[auto][j]\n",
    "            else:\n",
    "                pass\n",
    "    except: pass\n",
    "\n",
    "    try:\n",
    "        rev=[c for c in df.columns if \"REVERSE\" in str(c).upper() ][0]\n",
    "        for j,i in enumerate(df[rev]):\n",
    "            if isnan(i) == False:\n",
    "                df[dep][j] = df[rev][j]\n",
    "            else:\n",
    "                pass\n",
    "    except: pass\n",
    "    \n",
    "    df[dep]=df[dep].apply( lambda x: x.split(' ')[0] if type(x) == str else x )\n",
    "    df[wdl]=df[wdl].apply( lambda x: x.split(' ')[0] if type(x) == str else x )\n",
    "    df[wdl]=df[wdl].astype(str).apply(lambda x: str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float) *-1\n",
    "    df[dep]=df[dep].astype(str).apply(lambda x: str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float)\n",
    "    df[bal]=df[bal].astype(str).apply(lambda x:str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float)\n",
    "\n",
    "    try:\n",
    "        for i in df.index:\n",
    "        #     # create new column\n",
    "        #     if \"Dr\" in df[\"new_column\"][i].astype(str):\n",
    "        #         df[bal][i] = df[bal][i]*-1\n",
    "            if df[\"bal\"][i] == \"Dr\":\n",
    "                df[bal][i] = df[bal][i]*-1\n",
    "            else:\n",
    "                pass\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop(['bal'], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop([auto], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop([rev], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    df = df[[dat,chq,narr,wdl,dep,bal]]\n",
    "    df.columns = [\"Xns Date\",\"Cheque No\",\"Narration\",\"Debits\",\"Credits\",\"Balance\"]\n",
    "        \n",
    "    #df.to_csv(\"check_csv.csv\", index=0)\n",
    "    #df.to_xml(\"check_xml.xml\")\n",
    "    df.to_excel(\"icici09.xlsx\", index=False)\n",
    "\n",
    "f = r\"C:\\Users\\MudraCircle\\Desktop\\bks_raw\\Parsing_testing\\ICICI\\ICICI\\pattern_1\\icici09.pdf\"\n",
    "try:\n",
    "    df = icici_p1(f) ; df = icici_p1_process(df)\n",
    "    print(\"Parsed\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\",e)\n",
    "    print(\"Not Parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xml(df, filename=\"None.xml\", mode='w'):\n",
    "    def row_to_xml(row):\n",
    "        xml = ['<item>']\n",
    "        for i, col_name in enumerate(row.index):\n",
    "            xml.append('  <field name=\"{0}\">{1}</field>'.format(col_name, row.iloc[i]))\n",
    "        xml.append('</item>')\n",
    "        return '\\n'.join(xml)\n",
    "    res = '\\n'.join(df.apply(row_to_xml, axis=1))\n",
    "\n",
    "    if filename is None:\n",
    "        return res\n",
    "    with open(filename, mode) as f:\n",
    "        f.write(res)\n",
    "\n",
    "pd.DataFrame.to_xml = to_xml\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
